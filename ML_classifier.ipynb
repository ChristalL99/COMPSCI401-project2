{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f40b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8f2d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What colour is that virus? #coronavirus https:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don’t know if @Travistritt is taking request...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tiny minuscule droplets of #Covid19 🦠 can last...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have an old computer 💻 sitting around a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we pray God keeps us safe.. #BENNIE needs you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>@JeremyKonyndyk “The biggest variable in this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Let's fight against Corona Virus. SAHAJAYOGA M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>#IndiaFightsCorona  Know about the answers to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>#prepper  skills #CoronavirusPandemic https://...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>I can’t stop laughing 😂 @DaEntertainah85 @keen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9986 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  country\n",
       "0     What colour is that virus? #coronavirus https:...        0\n",
       "1     I don’t know if @Travistritt is taking request...        1\n",
       "2     Tiny minuscule droplets of #Covid19 🦠 can last...        0\n",
       "3     Do you have an old computer 💻 sitting around a...        0\n",
       "4     we pray God keeps us safe.. #BENNIE needs you ...        0\n",
       "...                                                 ...      ...\n",
       "9995  @JeremyKonyndyk “The biggest variable in this ...        0\n",
       "9996  Let's fight against Corona Virus. SAHAJAYOGA M...        0\n",
       "9997  #IndiaFightsCorona  Know about the answers to ...        0\n",
       "9998  #prepper  skills #CoronavirusPandemic https://...        1\n",
       "9999  I can’t stop laughing 😂 @DaEntertainah85 @keen...        1\n",
       "\n",
       "[9986 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"training.csv\",sep='\\;')\n",
    "train = train[[\"text\",\"country_code\"]]\n",
    "train = train.drop_duplicates()\n",
    "train[\"country\"] = 0\n",
    "train.loc[train[\"country_code\"] == 'US', 'country'] = 1\n",
    "train = train[[\"text\", \"country\"]]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52b44d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '00000375', ..., 'zzp6nrhjxp', 'zzsgy43rc0',\n",
       "       'zzw1h5cvqj'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase = True,\n",
    "                             strip_accents=\"ascii\", \n",
    "                             analyzer='word', \n",
    "                             stop_words='english', \n",
    "#                              max_features= 150000, \n",
    "                             max_df = 0.4,\n",
    "                             ngram_range=(1,1))\n",
    "X_train = vectorizer.fit_transform(train[\"text\"])\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61c32b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9986, 38503)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d1b1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_transformer = TfidfTransformer(use_idf=False).fit(X_train)\n",
    "# X_train_tf = tf_transformer.transform(X_train)\n",
    "# X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866dd154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9986, 38503)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer(use_idf=False, norm='l2',sublinear_tf=True)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9bf26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=0.476,fit_prior=False)\n",
    "# clf = svm.SVC(C=1.0, kernel='rbf', gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163f2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', vectorizer), \\\n",
    "                     ('tfidf', tfidf_transformer),\n",
    "                     ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411f7069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_df=0.4, stop_words='english',\n",
       "                                 strip_accents='ascii')),\n",
       "                ('tfidf', TfidfTransformer(sublinear_tf=True, use_idf=False)),\n",
       "                ('clf', MultinomialNB(alpha=0.476, fit_prior=False))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(train[\"text\"], train[\"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c3b0bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big trip 5 mi to north...checked out Yountvill...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think that @GovRonDeSantis is handling this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AdamSandler will you be having a ZOOM Seder t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Choudhary Family keeping themselves busy with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we pray God keeps us safe.. #BENNIE needs you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>I still don’t understand what privilege has to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>Just closed up shop for at least the next 30 d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001</th>\n",
       "      <td>See! Miracles do happen. The solis family was ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30002</th>\n",
       "      <td>🙏🏾 this is getting out of hand. 🤔 Prayers up t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30003</th>\n",
       "      <td>The more we learn about how incompetent Donald...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  country\n",
       "0      Big trip 5 mi to north...checked out Yountvill...        1\n",
       "1      I think that @GovRonDeSantis is handling this ...        1\n",
       "2      @AdamSandler will you be having a ZOOM Seder t...        0\n",
       "3      Choudhary Family keeping themselves busy with ...        0\n",
       "4      we pray God keeps us safe.. #BENNIE needs you ...        0\n",
       "...                                                  ...      ...\n",
       "29999  I still don’t understand what privilege has to...        1\n",
       "30000  Just closed up shop for at least the next 30 d...        1\n",
       "30001  See! Miracles do happen. The solis family was ...        1\n",
       "30002  🙏🏾 this is getting out of hand. 🤔 Prayers up t...        0\n",
       "30003  The more we learn about how incompetent Donald...        1\n",
       "\n",
       "[30004 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\",sep='\\;')\n",
    "test = test[[\"text\",\"country_code\"]]\n",
    "# test = test.drop_duplicates()\n",
    "test[\"country\"] = 0\n",
    "test.loc[test[\"country_code\"] == 'US', 'country'] = 1\n",
    "test = test[[\"text\", \"country\"]]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7507d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.781962405012665\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(test[\"text\"].astype(str))\n",
    "print(\"Accuracy: {}\".format(np.mean(predicted == test[\"country\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9afba536",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_clf.pickle', 'wb') as file:\n",
    "    pickle.dump(text_clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d56317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_clf.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "787712ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test[\"text\"].astype(str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
